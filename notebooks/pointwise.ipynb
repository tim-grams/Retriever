{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointwise Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from skopt.space import Integer\n",
    "from skopt.space import Real\n",
    "from skopt.space import Categorical\n",
    "sys.path.append(os.path.dirname((os.path.abspath(\"\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tim/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/tim/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/tim/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/tim/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from src.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    collection='data/processed/20_200_0_collection.pkl',\n",
    "    queries='data/processed/20_200_0_queries.pkl',\n",
    "    queries_val='data/processed/20_200_0_queries_val.pkl',\n",
    "    queries_test='data/processed/20_200_0_queries_test.pkl',\n",
    "    features='data/processed/20_200_0_features.pkl',\n",
    "    qrels_val='data/processed/20_200_0_qrels_val.pkl',\n",
    "    qrels_test='data/processed/20_200_0_qrels_test.pkl',\n",
    "    features_test='data/processed/20_200_0_features_test.pkl',\n",
    "    features_val='data/processed/20_200_0_features_val.pkl',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qID</th>\n",
       "      <th>pID</th>\n",
       "      <th>y</th>\n",
       "      <th>w2v_cosine</th>\n",
       "      <th>w2v_euclidean</th>\n",
       "      <th>w2v_manhattan</th>\n",
       "      <th>tfidf_cosine</th>\n",
       "      <th>tfidf_euclidean</th>\n",
       "      <th>tfidf_manhattan</th>\n",
       "      <th>bert_cosine</th>\n",
       "      <th>...</th>\n",
       "      <th>polarity_doc</th>\n",
       "      <th>subjectivity_query</th>\n",
       "      <th>polarity_query</th>\n",
       "      <th>bm25</th>\n",
       "      <th>doc_nouns</th>\n",
       "      <th>doc_adjectives</th>\n",
       "      <th>doc_verbs</th>\n",
       "      <th>query_nouns</th>\n",
       "      <th>query_adjectives</th>\n",
       "      <th>query_verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>603195</td>\n",
       "      <td>7050012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994196</td>\n",
       "      <td>65.315483</td>\n",
       "      <td>521.174474</td>\n",
       "      <td>0.496043</td>\n",
       "      <td>1.003949</td>\n",
       "      <td>4.459553</td>\n",
       "      <td>0.899372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-24.910609</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>474183</td>\n",
       "      <td>325505</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996240</td>\n",
       "      <td>70.790733</td>\n",
       "      <td>567.267506</td>\n",
       "      <td>0.740712</td>\n",
       "      <td>0.720123</td>\n",
       "      <td>2.745917</td>\n",
       "      <td>0.880772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-32.867280</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>320545</td>\n",
       "      <td>1751825</td>\n",
       "      <td>1</td>\n",
       "      <td>0.945538</td>\n",
       "      <td>42.384514</td>\n",
       "      <td>345.523735</td>\n",
       "      <td>0.462614</td>\n",
       "      <td>1.036712</td>\n",
       "      <td>3.490260</td>\n",
       "      <td>0.582573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-19.845336</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89798</td>\n",
       "      <td>5069949</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983225</td>\n",
       "      <td>86.804070</td>\n",
       "      <td>682.813968</td>\n",
       "      <td>0.528376</td>\n",
       "      <td>0.971209</td>\n",
       "      <td>5.262610</td>\n",
       "      <td>0.731121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-27.252681</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1054603</td>\n",
       "      <td>2869106</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986374</td>\n",
       "      <td>76.179581</td>\n",
       "      <td>607.961182</td>\n",
       "      <td>0.447341</td>\n",
       "      <td>1.051341</td>\n",
       "      <td>5.015437</td>\n",
       "      <td>0.774794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-28.400534</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1165107</td>\n",
       "      <td>2078953</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987960</td>\n",
       "      <td>68.098122</td>\n",
       "      <td>541.248789</td>\n",
       "      <td>0.453662</td>\n",
       "      <td>1.045312</td>\n",
       "      <td>4.689901</td>\n",
       "      <td>0.482285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.566152</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>309227</td>\n",
       "      <td>718432</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922373</td>\n",
       "      <td>43.735497</td>\n",
       "      <td>350.974023</td>\n",
       "      <td>0.706138</td>\n",
       "      <td>0.766632</td>\n",
       "      <td>2.630957</td>\n",
       "      <td>0.506990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-19.352811</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>594675</td>\n",
       "      <td>2996694</td>\n",
       "      <td>0</td>\n",
       "      <td>0.923053</td>\n",
       "      <td>37.689041</td>\n",
       "      <td>299.969996</td>\n",
       "      <td>0.247049</td>\n",
       "      <td>1.227152</td>\n",
       "      <td>3.557621</td>\n",
       "      <td>0.275192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.200606</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>905486</td>\n",
       "      <td>7669113</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993062</td>\n",
       "      <td>37.770847</td>\n",
       "      <td>306.176907</td>\n",
       "      <td>0.649830</td>\n",
       "      <td>0.836863</td>\n",
       "      <td>3.417697</td>\n",
       "      <td>0.554341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-28.045122</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>189977</td>\n",
       "      <td>6063531</td>\n",
       "      <td>0</td>\n",
       "      <td>0.969894</td>\n",
       "      <td>94.462494</td>\n",
       "      <td>759.860878</td>\n",
       "      <td>0.266714</td>\n",
       "      <td>1.211021</td>\n",
       "      <td>4.577297</td>\n",
       "      <td>0.441152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-18.478567</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         qID      pID  y  w2v_cosine  w2v_euclidean  w2v_manhattan  \\\n",
       "0     603195  7050012  1    0.994196      65.315483     521.174474   \n",
       "1     474183   325505  1    0.996240      70.790733     567.267506   \n",
       "2     320545  1751825  1    0.945538      42.384514     345.523735   \n",
       "3      89798  5069949  1    0.983225      86.804070     682.813968   \n",
       "4    1054603  2869106  1    0.986374      76.179581     607.961182   \n",
       "..       ...      ... ..         ...            ...            ...   \n",
       "195  1165107  2078953  0    0.987960      68.098122     541.248789   \n",
       "196   309227   718432  0    0.922373      43.735497     350.974023   \n",
       "197   594675  2996694  0    0.923053      37.689041     299.969996   \n",
       "198   905486  7669113  0    0.993062      37.770847     306.176907   \n",
       "199   189977  6063531  0    0.969894      94.462494     759.860878   \n",
       "\n",
       "     tfidf_cosine  tfidf_euclidean  tfidf_manhattan  bert_cosine  ...  \\\n",
       "0        0.496043         1.003949         4.459553     0.899372  ...   \n",
       "1        0.740712         0.720123         2.745917     0.880772  ...   \n",
       "2        0.462614         1.036712         3.490260     0.582573  ...   \n",
       "3        0.528376         0.971209         5.262610     0.731121  ...   \n",
       "4        0.447341         1.051341         5.015437     0.774794  ...   \n",
       "..            ...              ...              ...          ...  ...   \n",
       "195      0.453662         1.045312         4.689901     0.482285  ...   \n",
       "196      0.706138         0.766632         2.630957     0.506990  ...   \n",
       "197      0.247049         1.227152         3.557621     0.275192  ...   \n",
       "198      0.649830         0.836863         3.417697     0.554341  ...   \n",
       "199      0.266714         1.211021         4.577297     0.441152  ...   \n",
       "\n",
       "     polarity_doc  subjectivity_query  polarity_query       bm25  doc_nouns  \\\n",
       "0        0.000000                0.00             0.0 -24.910609         23   \n",
       "1        0.450000                0.00             0.0 -32.867280         18   \n",
       "2        0.500000                0.20             0.2 -19.845336         20   \n",
       "3        0.066667                0.25             0.0 -27.252681         25   \n",
       "4        0.000000                0.00             0.0 -28.400534         20   \n",
       "..            ...                 ...             ...        ...        ...   \n",
       "195      0.113333                0.00             0.0 -10.566152         14   \n",
       "196      0.362500                0.20             0.2 -19.352811         14   \n",
       "197      0.125000                0.00             0.0 -10.200606         15   \n",
       "198      0.150000                0.00             0.0 -28.045122          7   \n",
       "199     -0.020000                0.00             0.0 -18.478567         14   \n",
       "\n",
       "     doc_adjectives  doc_verbs  query_nouns  query_adjectives  query_verbs  \n",
       "0                 6          4            3                 1            1  \n",
       "1                 9          3            4                 0            0  \n",
       "2                 2         14            2                 1            1  \n",
       "3                10          5            3                 1            0  \n",
       "4                 9          6            2                 2            1  \n",
       "..              ...        ...          ...               ...          ...  \n",
       "195               7          5            1                 0            2  \n",
       "196               8         10            3                 1            1  \n",
       "197               6          6            1                 1            1  \n",
       "198               7          6            2                 1            2  \n",
       "199               8         19            2                 1            1  \n",
       "\n",
       "[400 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.0009609179551511558\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    model='lr', \n",
    "    pca=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_search_space: list = []\n",
    "logistic_regression_search_space.append(Categorical(['l2', 'none'], name='penalty'))\n",
    "logistic_regression_search_space.append(Real(0.1, 100.0, name='C'))\n",
    "logistic_regression_search_space.append(Real(1e-6, 0.1, name='tol'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MRR: 0.0004853499004727582\n",
      "Best Hyperparameters: ['none', 37.07012583093926, 0.05146727586830882]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR on test set: 0.0009793445012636875\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    model='lr', \n",
    "    pca=5, \n",
    "    search_space=logistic_regression_search_space\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.00037925096247957166\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    model='nb', \n",
    "    pca=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.0002246908580758419\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    model='mlp', \n",
    "    pca=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_search_space: list = []\n",
    "mlp_search_space.append(Categorical(['identity', 'logistic', 'tanh', 'relu'], name='activation'))\n",
    "mlp_search_space.append(Real(1e-6, 0.1, name='alpha'))\n",
    "mlp_search_space.append(Real(1e-6, 0.1, name='learning_rate_init'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MRR: 1.5322396602475802e-05\n",
      "Best Hyperparameters: ['tanh', 0.1, 1e-06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR on test set: 1.550861175175541e-05\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    model='mlp', \n",
    "    pca=0,\n",
    "    search_space=mlp_search_space\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>pairwise_model</th>\n",
       "      <th>pairwise_k</th>\n",
       "      <th>features</th>\n",
       "      <th>sampling_training</th>\n",
       "      <th>sampling_test</th>\n",
       "      <th>pca</th>\n",
       "      <th>MRR</th>\n",
       "      <th>MAP</th>\n",
       "      <th>nDCG</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy@50</th>\n",
       "      <th>precision@50</th>\n",
       "      <th>recall@50</th>\n",
       "      <th>f1@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>{\"C\": 1.0, \"class_weight\": null, \"dual\": false...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>400</td>\n",
       "      <td>65340</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.889781</td>\n",
       "      <td>0.872598</td>\n",
       "      <td>0.986532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.335347</td>\n",
       "      <td>0.502262</td>\n",
       "      <td>0.769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>0.772414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>{\"priors\": null, \"var_smoothing\": 1e-09}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"pca_comp_0\", \"pca_comp_1\", \"pca_comp_2\", \"pc...</td>\n",
       "      <td>400</td>\n",
       "      <td>65340</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.606719</td>\n",
       "      <td>0.835205</td>\n",
       "      <td>0.984206</td>\n",
       "      <td>0.762590</td>\n",
       "      <td>0.320242</td>\n",
       "      <td>0.451064</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.748954</td>\n",
       "      <td>0.681905</td>\n",
       "      <td>0.713858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLPClassifier()</td>\n",
       "      <td>{\"activation\": \"relu\", \"alpha\": 0.0001, \"batch...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>400</td>\n",
       "      <td>65340</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.512187</td>\n",
       "      <td>0.781183</td>\n",
       "      <td>0.958402</td>\n",
       "      <td>0.211745</td>\n",
       "      <td>0.386707</td>\n",
       "      <td>0.273650</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.441476</td>\n",
       "      <td>0.971989</td>\n",
       "      <td>0.607174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPClassifier(activation='tanh', alpha=0.1, le...</td>\n",
       "      <td>{\"activation\": \"tanh\", \"alpha\": 0.1, \"batch_si...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>400</td>\n",
       "      <td>65340</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>0.475238</td>\n",
       "      <td>0.604239</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.152568</td>\n",
       "      <td>0.015383</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  \\\n",
       "0                               LogisticRegression()   \n",
       "1                                       GaussianNB()   \n",
       "2                                    MLPClassifier()   \n",
       "3  MLPClassifier(activation='tanh', alpha=0.1, le...   \n",
       "\n",
       "                                     hyperparameters pairwise_model  \\\n",
       "0  {\"C\": 1.0, \"class_weight\": null, \"dual\": false...           None   \n",
       "1           {\"priors\": null, \"var_smoothing\": 1e-09}           None   \n",
       "2  {\"activation\": \"relu\", \"alpha\": 0.0001, \"batch...           None   \n",
       "3  {\"activation\": \"tanh\", \"alpha\": 0.1, \"batch_si...           None   \n",
       "\n",
       "  pairwise_k                                           features  \\\n",
       "0       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "1       None  [\"pca_comp_0\", \"pca_comp_1\", \"pca_comp_2\", \"pc...   \n",
       "2       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "3       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "\n",
       "   sampling_training  sampling_test  pca       MRR       MAP      nDCG  \\\n",
       "0                400          65340    0  0.000961  0.889781  0.872598   \n",
       "1                400          65340   10  0.000379  0.606719  0.835205   \n",
       "2                400          65340    0  0.000225  0.512187  0.781183   \n",
       "3                400          65340    0  0.000016  0.011657  0.475238   \n",
       "\n",
       "   accuracy  precision    recall        f1  accuracy@50  precision@50  \\\n",
       "0  0.986532   1.000000  0.335347  0.502262        0.769      1.000000   \n",
       "1  0.984206   0.762590  0.320242  0.451064        0.713      0.748954   \n",
       "2  0.958402   0.211745  0.386707  0.273650        0.551      0.441476   \n",
       "3  0.604239   0.008100  0.152568  0.015383        0.014      0.000000   \n",
       "\n",
       "   recall@50     f1@50  \n",
       "0   0.629213  0.772414  \n",
       "1   0.681905  0.713858  \n",
       "2   0.971989  0.607174  \n",
       "3        NaN       NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.utils.utils import load\n",
    "\n",
    "results = load('data/results/results.pkl')\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15e7f6431c3efcc25ffb982d882caeeee1a07ee55caab724c679dfe0992cca8b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}