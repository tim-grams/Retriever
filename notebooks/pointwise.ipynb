{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointwise Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, pointwise algorithms can be evaluated.\n",
    "To start an experiment, define it using the following parameters:\n",
    "\n",
    "<b>name</b>: Name of the experiment <br>\n",
    "<b>model</b>: The model to use (Possible choices are ) <br>\n",
    "<b>pca</b>: PCA components for dimensionality reduction (None with 0) <br>\n",
    "<b>search_space</b>: Values to use in bayesian optimization (Optional) <br>\n",
    "<b>trials</b>: Number of hyperparameter optimization trials (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from skopt.space import Integer\n",
    "from skopt.space import Real\n",
    "from skopt.space import Categorical\n",
    "sys.path.append(os.path.dirname((os.path.abspath(\"\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tim/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/tim/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/tim/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/tim/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from src.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    collection='data/processed/30_5000_1000_collection.pkl',\n",
    "    queries='data/processed/30_5000_1000_queries.pkl',\n",
    "    queries_val='data/processed/30_5000_1000_queries_val.pkl',\n",
    "    queries_test='data/processed/30_5000_1000_queries_test.pkl',\n",
    "    features='data/processed/30_5000_1000_features.pkl',\n",
    "    qrels_val='data/processed/30_5000_1000_qrels_val.pkl',\n",
    "    qrels_test='data/processed/30_5000_1000_qrels_test.pkl',\n",
    "    features_test='data/processed/30_5000_1000_features_test.pkl',\n",
    "    features_val='data/processed/30_5000_1000_features_val.pkl',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qID</th>\n",
       "      <th>pID</th>\n",
       "      <th>y</th>\n",
       "      <th>w2v_cosine</th>\n",
       "      <th>w2v_euclidean</th>\n",
       "      <th>w2v_manhattan</th>\n",
       "      <th>w2v_tfidf_cosine</th>\n",
       "      <th>w2v_tfidf_euclidean</th>\n",
       "      <th>w2v_tfidf_manhattan</th>\n",
       "      <th>tfidf_cosine</th>\n",
       "      <th>...</th>\n",
       "      <th>polarity_doc</th>\n",
       "      <th>subjectivity_query</th>\n",
       "      <th>polarity_query</th>\n",
       "      <th>bm25</th>\n",
       "      <th>doc_nouns</th>\n",
       "      <th>doc_adjectives</th>\n",
       "      <th>doc_verbs</th>\n",
       "      <th>query_nouns</th>\n",
       "      <th>query_adjectives</th>\n",
       "      <th>query_verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>603195</td>\n",
       "      <td>7050012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.972107</td>\n",
       "      <td>144.641830</td>\n",
       "      <td>1124.871630</td>\n",
       "      <td>0.938781</td>\n",
       "      <td>2.765727</td>\n",
       "      <td>22.236694</td>\n",
       "      <td>0.537439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-24.655536</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>474183</td>\n",
       "      <td>325505</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971866</td>\n",
       "      <td>131.960266</td>\n",
       "      <td>1033.670312</td>\n",
       "      <td>0.985675</td>\n",
       "      <td>1.360485</td>\n",
       "      <td>11.347487</td>\n",
       "      <td>0.745907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-33.129796</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>320545</td>\n",
       "      <td>1751825</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947701</td>\n",
       "      <td>94.900002</td>\n",
       "      <td>756.378183</td>\n",
       "      <td>0.959522</td>\n",
       "      <td>2.236971</td>\n",
       "      <td>17.352688</td>\n",
       "      <td>0.409509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-16.699603</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89798</td>\n",
       "      <td>5069949</td>\n",
       "      <td>1</td>\n",
       "      <td>0.972710</td>\n",
       "      <td>161.470459</td>\n",
       "      <td>1273.643564</td>\n",
       "      <td>0.933304</td>\n",
       "      <td>1.714253</td>\n",
       "      <td>13.493497</td>\n",
       "      <td>0.541627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-27.678576</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1054603</td>\n",
       "      <td>2869106</td>\n",
       "      <td>1</td>\n",
       "      <td>0.965680</td>\n",
       "      <td>155.648453</td>\n",
       "      <td>1216.564726</td>\n",
       "      <td>0.941391</td>\n",
       "      <td>1.799412</td>\n",
       "      <td>14.369308</td>\n",
       "      <td>0.438115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-28.497519</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>128401</td>\n",
       "      <td>6127598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.796978</td>\n",
       "      <td>85.670822</td>\n",
       "      <td>678.466760</td>\n",
       "      <td>0.555981</td>\n",
       "      <td>3.027138</td>\n",
       "      <td>24.841764</td>\n",
       "      <td>0.185056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.520833</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-8.866170</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1044540</td>\n",
       "      <td>4616118</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922095</td>\n",
       "      <td>157.044754</td>\n",
       "      <td>1238.354322</td>\n",
       "      <td>0.603788</td>\n",
       "      <td>2.167866</td>\n",
       "      <td>17.812756</td>\n",
       "      <td>0.140057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-7.852468</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>486146</td>\n",
       "      <td>1137390</td>\n",
       "      <td>0</td>\n",
       "      <td>0.946438</td>\n",
       "      <td>125.126984</td>\n",
       "      <td>972.330644</td>\n",
       "      <td>0.882998</td>\n",
       "      <td>4.161341</td>\n",
       "      <td>34.815641</td>\n",
       "      <td>0.314505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-15.909103</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>532697</td>\n",
       "      <td>5161847</td>\n",
       "      <td>0</td>\n",
       "      <td>0.938939</td>\n",
       "      <td>99.808395</td>\n",
       "      <td>790.453814</td>\n",
       "      <td>0.893834</td>\n",
       "      <td>1.977307</td>\n",
       "      <td>16.122506</td>\n",
       "      <td>0.344173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284375</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-16.617979</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>763472</td>\n",
       "      <td>6447198</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988622</td>\n",
       "      <td>134.510406</td>\n",
       "      <td>1094.769867</td>\n",
       "      <td>0.977100</td>\n",
       "      <td>1.039390</td>\n",
       "      <td>8.350440</td>\n",
       "      <td>0.290261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-16.757101</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9977 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          qID      pID  y  w2v_cosine  w2v_euclidean  w2v_manhattan  \\\n",
       "0      603195  7050012  1    0.972107     144.641830    1124.871630   \n",
       "1      474183   325505  1    0.971866     131.960266    1033.670312   \n",
       "2      320545  1751825  1    0.947701      94.900002     756.378183   \n",
       "3       89798  5069949  1    0.972710     161.470459    1273.643564   \n",
       "4     1054603  2869106  1    0.965680     155.648453    1216.564726   \n",
       "...       ...      ... ..         ...            ...            ...   \n",
       "4995   128401  6127598  0    0.796978      85.670822     678.466760   \n",
       "4996  1044540  4616118  0    0.922095     157.044754    1238.354322   \n",
       "4997   486146  1137390  0    0.946438     125.126984     972.330644   \n",
       "4998   532697  5161847  0    0.938939      99.808395     790.453814   \n",
       "4999   763472  6447198  0    0.988622     134.510406    1094.769867   \n",
       "\n",
       "      w2v_tfidf_cosine  w2v_tfidf_euclidean  w2v_tfidf_manhattan  \\\n",
       "0             0.938781             2.765727            22.236694   \n",
       "1             0.985675             1.360485            11.347487   \n",
       "2             0.959522             2.236971            17.352688   \n",
       "3             0.933304             1.714253            13.493497   \n",
       "4             0.941391             1.799412            14.369308   \n",
       "...                ...                  ...                  ...   \n",
       "4995          0.555981             3.027138            24.841764   \n",
       "4996          0.603788             2.167866            17.812756   \n",
       "4997          0.882998             4.161341            34.815641   \n",
       "4998          0.893834             1.977307            16.122506   \n",
       "4999          0.977100             1.039390             8.350440   \n",
       "\n",
       "      tfidf_cosine  ...  polarity_doc  subjectivity_query  polarity_query  \\\n",
       "0         0.537439  ...      0.000000                0.00            0.00   \n",
       "1         0.745907  ...      0.450000                0.00            0.00   \n",
       "2         0.409509  ...      0.500000                0.20            0.20   \n",
       "3         0.541627  ...      0.066667                0.25            0.00   \n",
       "4         0.438115  ...      0.000000                0.00            0.00   \n",
       "...            ...  ...           ...                 ...             ...   \n",
       "4995      0.185056  ...     -0.520833                0.00            0.00   \n",
       "4996      0.140057  ...      0.156250                0.00            0.00   \n",
       "4997      0.314505  ...     -0.100000                0.10            0.00   \n",
       "4998      0.344173  ...      0.284375                0.00            0.00   \n",
       "4999      0.290261  ...      0.033333                0.05            0.15   \n",
       "\n",
       "           bm25  doc_nouns  doc_adjectives  doc_verbs  query_nouns  \\\n",
       "0    -24.655536         23               6          4            3   \n",
       "1    -33.129796         18               9          3            4   \n",
       "2    -16.699603         20               2         14            2   \n",
       "3    -27.678576         25              10          5            3   \n",
       "4    -28.497519         20               9          6            2   \n",
       "...         ...        ...             ...        ...          ...   \n",
       "4995  -8.866170         16               6         13            2   \n",
       "4996  -7.852468         25               9         16            0   \n",
       "4997 -15.909103         12               1         10            2   \n",
       "4998 -16.617979         18               8          9            3   \n",
       "4999 -16.757101         12              16          4            1   \n",
       "\n",
       "      query_adjectives  query_verbs  \n",
       "0                    1            1  \n",
       "1                    0            0  \n",
       "2                    1            1  \n",
       "3                    1            0  \n",
       "4                    2            1  \n",
       "...                ...          ...  \n",
       "4995                 1            0  \n",
       "4996                 0            1  \n",
       "4997                 0            2  \n",
       "4998                 1            0  \n",
       "4999                 3            1  \n",
       "\n",
       "[9977 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.03805952869994696\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='default',\n",
    "    model='lr', \n",
    "    pca=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_search_space: list = []\n",
    "logistic_regression_search_space.append(Categorical(['l2', 'none'], name='penalty'))\n",
    "logistic_regression_search_space.append(Real(0.1, 100.0, name='C'))\n",
    "logistic_regression_search_space.append(Real(1e-6, 0.1, name='tol'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MRR: -0.020961472527053267\n",
      "Best Hyperparameters: ['l2', 5.6980759407867705, 0.002508188700257655]\n",
      "MRR on test set: 0.037126943017010396\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='hpo',\n",
    "    model='lr', \n",
    "    pca=5, \n",
    "    search_space=logistic_regression_search_space,\n",
    "    trials=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.011993873274804862\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='default',\n",
    "    model='nbg', \n",
    "    pca=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.020524026657751986\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='default',\n",
    "    model='mlp', \n",
    "    pca=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_search_space: list = []\n",
    "mlp_search_space.append(Categorical(['identity', 'logistic', 'tanh', 'relu'], name='activation'))\n",
    "mlp_search_space.append(Real(1e-6, 0.1, name='alpha'))\n",
    "mlp_search_space.append(Real(1e-6, 0.1, name='learning_rate_init'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MRR: 0.008856659110087957\n",
      "Best Hyperparameters: ['relu', 0.0057874644134355835, 0.0478341107632347]\n",
      "MRR on test set: 0.029243423005499914\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='hpo',\n",
    "    model='mlp', \n",
    "    pca=0,\n",
    "    search_space=mlp_search_space,\n",
    "    trials=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.0319047903484395\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='default',\n",
    "    model='svm', \n",
    "    pca=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_search_space: list = []\n",
    "svm_search_space.append(Categorical(['poly', 'rbf', 'sigmoid'], name='kernel'))\n",
    "svm_search_space.append(Real(0.1, 100.0, name='C'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MRR: 0.006591189472904975\n",
      "Best Hyperparameters: ['poly', 96.43409248718199]\n",
      "MRR on test set: 0.02065391377002617\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    model='svm', \n",
    "    pca=0,\n",
    "    search_space=svm_search_space,\n",
    "    trials=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.005629759821865629\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='default',\n",
    "    model='dt', \n",
    "    pca=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_search_space: list = []\n",
    "decision_tree_search_space.append(Categorical(['gini', 'entropy'], name='criterion'))\n",
    "decision_tree_search_space.append(Integer(2, 15, name='min_samples_split'))\n",
    "decision_tree_search_space.append(Integer(1, 10, name='min_samples_leaf'))\n",
    "decision_tree_search_space.append(Integer(5, 100, name='max_leaf_nodes'))\n",
    "decision_tree_search_space.append(Integer(10, 50, name='max_depth'))\n",
    "decision_tree_search_space.append(Real(0.0, 0.2, name='min_weight_fraction_leaf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MRR: -0.013578619748480097\n",
      "Best Hyperparameters: ['entropy', 8, 10, 46, 48, 0.190366916117415]\n",
      "MRR on test set: 0.02660054996605312\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    model='dt', \n",
    "    pca=0,\n",
    "    search_space=decision_tree_search_space\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.016968704538821933\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='default',\n",
    "    model='rf', \n",
    "    pca=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.03265656237712727\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='default',\n",
    "    model='ada', \n",
    "    pca=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.024774278238366358\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='default',\n",
    "    model='gb', \n",
    "    pca=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.utils.utils import load\n",
    "\n",
    "results = load('data/results/results.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>pairwise_model</th>\n",
       "      <th>pairwise_k</th>\n",
       "      <th>features</th>\n",
       "      <th>sampling_training</th>\n",
       "      <th>sampling_test</th>\n",
       "      <th>pca</th>\n",
       "      <th>MRR</th>\n",
       "      <th>MAP</th>\n",
       "      <th>nDCG</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy@50</th>\n",
       "      <th>precision@50</th>\n",
       "      <th>recall@50</th>\n",
       "      <th>f1@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038060</td>\n",
       "      <td>0.865090</td>\n",
       "      <td>0.859446</td>\n",
       "      <td>0.997135</td>\n",
       "      <td>0.993724</td>\n",
       "      <td>0.268969</td>\n",
       "      <td>0.423351</td>\n",
       "      <td>0.690667</td>\n",
       "      <td>0.993289</td>\n",
       "      <td>0.490608</td>\n",
       "      <td>0.656805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>default</td>\n",
       "      <td>MLPClassifier()</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024653</td>\n",
       "      <td>0.730808</td>\n",
       "      <td>0.810906</td>\n",
       "      <td>0.997206</td>\n",
       "      <td>0.921405</td>\n",
       "      <td>0.312005</td>\n",
       "      <td>0.466159</td>\n",
       "      <td>0.782000</td>\n",
       "      <td>0.920863</td>\n",
       "      <td>0.644025</td>\n",
       "      <td>0.757957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>default</td>\n",
       "      <td>MLPClassifier()</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020524</td>\n",
       "      <td>0.508995</td>\n",
       "      <td>0.691823</td>\n",
       "      <td>0.994098</td>\n",
       "      <td>0.284276</td>\n",
       "      <td>0.335787</td>\n",
       "      <td>0.307892</td>\n",
       "      <td>0.610667</td>\n",
       "      <td>0.495816</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.618799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>default</td>\n",
       "      <td>SVC(probability=True)</td>\n",
       "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031905</td>\n",
       "      <td>0.775301</td>\n",
       "      <td>0.826090</td>\n",
       "      <td>0.997206</td>\n",
       "      <td>0.994118</td>\n",
       "      <td>0.287089</td>\n",
       "      <td>0.445518</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.993763</td>\n",
       "      <td>0.560375</td>\n",
       "      <td>0.716642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>default</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>0.378551</td>\n",
       "      <td>0.613492</td>\n",
       "      <td>0.997000</td>\n",
       "      <td>0.739790</td>\n",
       "      <td>0.359003</td>\n",
       "      <td>0.483416</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.742156</td>\n",
       "      <td>0.998165</td>\n",
       "      <td>0.851330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>default</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>0.664969</td>\n",
       "      <td>0.791973</td>\n",
       "      <td>0.997445</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.348811</td>\n",
       "      <td>0.516345</td>\n",
       "      <td>0.864667</td>\n",
       "      <td>0.992995</td>\n",
       "      <td>0.740209</td>\n",
       "      <td>0.848168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>default</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032657</td>\n",
       "      <td>0.827516</td>\n",
       "      <td>0.854278</td>\n",
       "      <td>0.997219</td>\n",
       "      <td>0.992278</td>\n",
       "      <td>0.291053</td>\n",
       "      <td>0.450088</td>\n",
       "      <td>0.718667</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.532438</td>\n",
       "      <td>0.692868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>default</td>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024774</td>\n",
       "      <td>0.728408</td>\n",
       "      <td>0.826549</td>\n",
       "      <td>0.997246</td>\n",
       "      <td>0.992453</td>\n",
       "      <td>0.297848</td>\n",
       "      <td>0.458188</td>\n",
       "      <td>0.771333</td>\n",
       "      <td>0.991886</td>\n",
       "      <td>0.590580</td>\n",
       "      <td>0.740348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name                         model  \\\n",
       "0  default          LogisticRegression()   \n",
       "1  default               MLPClassifier()   \n",
       "2  default               MLPClassifier()   \n",
       "3  default         SVC(probability=True)   \n",
       "4  default      DecisionTreeClassifier()   \n",
       "5  default      RandomForestClassifier()   \n",
       "6  default          AdaBoostClassifier()   \n",
       "7  default  GradientBoostingClassifier()   \n",
       "\n",
       "                                     hyperparameters pairwise_model  \\\n",
       "0  {'C': 1.0, 'class_weight': None, 'dual': False...           None   \n",
       "1  {'activation': 'relu', 'alpha': 0.0001, 'batch...           None   \n",
       "2  {'activation': 'relu', 'alpha': 0.0001, 'batch...           None   \n",
       "3  {'C': 1.0, 'break_ties': False, 'cache_size': ...           None   \n",
       "4  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...           None   \n",
       "5  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...           None   \n",
       "6  {'algorithm': 'SAMME.R', 'base_estimator': Non...           None   \n",
       "7  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...           None   \n",
       "\n",
       "  pairwise_k                                           features  \\\n",
       "0       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "1       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "2       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "3       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "4       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "5       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "6       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "7       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "\n",
       "   sampling_training  sampling_test  pca       MRR       MAP      nDCG  \\\n",
       "0               9977         451680    0  0.038060  0.865090  0.859446   \n",
       "1               9977         451680    0  0.024653  0.730808  0.810906   \n",
       "2               9977         451680    0  0.020524  0.508995  0.691823   \n",
       "3               9977         451680    0  0.031905  0.775301  0.826090   \n",
       "4               9977         451680    0  0.005630  0.378551  0.613492   \n",
       "5               9977         451680    0  0.016969  0.664969  0.791973   \n",
       "6               9977         451680    0  0.032657  0.827516  0.854278   \n",
       "7               9977         451680    0  0.024774  0.728408  0.826549   \n",
       "\n",
       "   accuracy  precision    recall        f1  accuracy@50  precision@50  \\\n",
       "0  0.997135   0.993724  0.268969  0.423351     0.690667      0.993289   \n",
       "1  0.997206   0.921405  0.312005  0.466159     0.782000      0.920863   \n",
       "2  0.994098   0.284276  0.335787  0.307892     0.610667      0.495816   \n",
       "3  0.997206   0.994118  0.287089  0.445518     0.748000      0.993763   \n",
       "4  0.997000   0.739790  0.359003  0.483416     0.873333      0.742156   \n",
       "5  0.997445   0.993548  0.348811  0.516345     0.864667      0.992995   \n",
       "6  0.997219   0.992278  0.291053  0.450088     0.718667      0.991667   \n",
       "7  0.997246   0.992453  0.297848  0.458188     0.771333      0.991886   \n",
       "\n",
       "   recall@50     f1@50  \n",
       "0   0.490608  0.656805  \n",
       "1   0.644025  0.757957  \n",
       "2   0.822917  0.618799  \n",
       "3   0.560375  0.716642  \n",
       "4   0.998165  0.851330  \n",
       "5   0.740209  0.848168  \n",
       "6   0.532438  0.692868  \n",
       "7   0.590580  0.740348  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['name'] == 'default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>pairwise_model</th>\n",
       "      <th>pairwise_k</th>\n",
       "      <th>features</th>\n",
       "      <th>sampling_training</th>\n",
       "      <th>sampling_test</th>\n",
       "      <th>pca</th>\n",
       "      <th>MRR</th>\n",
       "      <th>MAP</th>\n",
       "      <th>nDCG</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy@50</th>\n",
       "      <th>precision@50</th>\n",
       "      <th>recall@50</th>\n",
       "      <th>f1@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>hpo</td>\n",
       "      <td>LogisticRegression(C=0.10099145980936619, tol=...</td>\n",
       "      <td>{\"C\": 0.10099145980936619, \"class_weight\": nul...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"pca_comp_0\", \"pca_comp_1\", \"pca_comp_2\", \"pc...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>5</td>\n",
       "      <td>0.037135</td>\n",
       "      <td>0.882746</td>\n",
       "      <td>0.871568</td>\n",
       "      <td>0.996918</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>0.212911</td>\n",
       "      <td>0.350746</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>0.412733</td>\n",
       "      <td>0.583398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name                                              model  \\\n",
       "25  hpo  LogisticRegression(C=0.10099145980936619, tol=...   \n",
       "\n",
       "                                      hyperparameters pairwise_model  \\\n",
       "25  {\"C\": 0.10099145980936619, \"class_weight\": nul...           None   \n",
       "\n",
       "   pairwise_k                                           features  \\\n",
       "25       None  [\"pca_comp_0\", \"pca_comp_1\", \"pca_comp_2\", \"pc...   \n",
       "\n",
       "    sampling_training  sampling_test  pca       MRR       MAP      nDCG  \\\n",
       "25               9977         451680    5  0.037135  0.882746  0.871568   \n",
       "\n",
       "    accuracy  precision    recall        f1  accuracy@50  precision@50  \\\n",
       "25  0.996918   0.994709  0.212911  0.350746        0.642      0.994709   \n",
       "\n",
       "    recall@50     f1@50  \n",
       "25   0.412733  0.583398  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['name'] == 'hpo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15e7f6431c3efcc25ffb982d882caeeee1a07ee55caab724c679dfe0992cca8b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
