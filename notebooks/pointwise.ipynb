{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointwise Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, pointwise algorithms can be evaluated.\n",
    "To start an experiment, define it using the following parameters:\n",
    "\n",
    "<b>name</b>: Name of the experiment <br>\n",
    "<b>model</b>: The model to use (Possible choices are nbg, lr, svm, dt, rf, ada, gb) <br>\n",
    "<b>pca</b>: PCA components for dimensionality reduction (None with 0) <br>\n",
    "<b>search_space</b>: Values to use in bayesian optimization (Optional) <br>\n",
    "<b>trials</b>: Number of hyperparameter optimization trials (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from skopt.space import Integer\n",
    "from skopt.space import Real\n",
    "from skopt.space import Categorical\n",
    "sys.path.append(os.path.dirname((os.path.abspath(\"\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tim/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/tim/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/tim/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/tim/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from src.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    collection='data/processed/30_5000_1000_collection.pkl',\n",
    "    queries='data/processed/30_5000_1000_queries.pkl',\n",
    "    queries_val='data/processed/30_5000_1000_queries_val.pkl',\n",
    "    queries_test='data/processed/30_5000_1000_queries_test.pkl',\n",
    "    features='data/processed/30_5000_1000_features.pkl',\n",
    "    qrels_val='data/processed/30_5000_1000_qrels_val.pkl',\n",
    "    qrels_test='data/processed/30_5000_1000_qrels_test.pkl',\n",
    "    features_test='data/processed/30_5000_1000_features_test.pkl',\n",
    "    features_val='data/processed/30_5000_1000_features_val.pkl',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>!</b> Run the next line only for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_result = ['bert_cosine', 'bm25', 'char_query', 'tfidf_manhattan', 'w2v_tfidf_manhattan', 'words_difference', 'query_nouns', 'query_adjectives', 'jaccard', 'w2v_cosine', 'query_verbs', 'doc_nouns', 'polarity_doc', 'words_rel_difference']\n",
    "pipeline.features = pipeline.features[['qID', 'pID', 'y'] + feature_selection_result]\n",
    "pipeline.features_test = pipeline.features_test[['qID', 'pID'] + feature_selection_result]\n",
    "pipeline.features_val = pipeline.features_val[['qID', 'pID'] + feature_selection_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qID</th>\n",
       "      <th>pID</th>\n",
       "      <th>y</th>\n",
       "      <th>w2v_cosine</th>\n",
       "      <th>w2v_euclidean</th>\n",
       "      <th>w2v_manhattan</th>\n",
       "      <th>w2v_tfidf_cosine</th>\n",
       "      <th>w2v_tfidf_euclidean</th>\n",
       "      <th>w2v_tfidf_manhattan</th>\n",
       "      <th>tfidf_cosine</th>\n",
       "      <th>...</th>\n",
       "      <th>polarity_doc</th>\n",
       "      <th>subjectivity_query</th>\n",
       "      <th>polarity_query</th>\n",
       "      <th>bm25</th>\n",
       "      <th>doc_nouns</th>\n",
       "      <th>doc_adjectives</th>\n",
       "      <th>doc_verbs</th>\n",
       "      <th>query_nouns</th>\n",
       "      <th>query_adjectives</th>\n",
       "      <th>query_verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>603195</td>\n",
       "      <td>7050012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.972107</td>\n",
       "      <td>144.641830</td>\n",
       "      <td>1124.871630</td>\n",
       "      <td>0.938781</td>\n",
       "      <td>2.765727</td>\n",
       "      <td>22.236694</td>\n",
       "      <td>0.537439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-24.655536</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>474183</td>\n",
       "      <td>325505</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971866</td>\n",
       "      <td>131.960266</td>\n",
       "      <td>1033.670312</td>\n",
       "      <td>0.985675</td>\n",
       "      <td>1.360485</td>\n",
       "      <td>11.347487</td>\n",
       "      <td>0.745907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-33.129796</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>320545</td>\n",
       "      <td>1751825</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947701</td>\n",
       "      <td>94.900002</td>\n",
       "      <td>756.378183</td>\n",
       "      <td>0.959522</td>\n",
       "      <td>2.236971</td>\n",
       "      <td>17.352688</td>\n",
       "      <td>0.409509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-16.699603</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89798</td>\n",
       "      <td>5069949</td>\n",
       "      <td>1</td>\n",
       "      <td>0.972710</td>\n",
       "      <td>161.470459</td>\n",
       "      <td>1273.643564</td>\n",
       "      <td>0.933304</td>\n",
       "      <td>1.714253</td>\n",
       "      <td>13.493497</td>\n",
       "      <td>0.541627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-27.678576</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1054603</td>\n",
       "      <td>2869106</td>\n",
       "      <td>1</td>\n",
       "      <td>0.965680</td>\n",
       "      <td>155.648453</td>\n",
       "      <td>1216.564726</td>\n",
       "      <td>0.941391</td>\n",
       "      <td>1.799412</td>\n",
       "      <td>14.369308</td>\n",
       "      <td>0.438115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-28.497519</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>128401</td>\n",
       "      <td>6127598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.796978</td>\n",
       "      <td>85.670822</td>\n",
       "      <td>678.466760</td>\n",
       "      <td>0.555981</td>\n",
       "      <td>3.027138</td>\n",
       "      <td>24.841764</td>\n",
       "      <td>0.185056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.520833</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-8.866170</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1044540</td>\n",
       "      <td>4616118</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922095</td>\n",
       "      <td>157.044754</td>\n",
       "      <td>1238.354322</td>\n",
       "      <td>0.603788</td>\n",
       "      <td>2.167866</td>\n",
       "      <td>17.812756</td>\n",
       "      <td>0.140057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-7.852468</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>486146</td>\n",
       "      <td>1137390</td>\n",
       "      <td>0</td>\n",
       "      <td>0.946438</td>\n",
       "      <td>125.126984</td>\n",
       "      <td>972.330644</td>\n",
       "      <td>0.882998</td>\n",
       "      <td>4.161341</td>\n",
       "      <td>34.815641</td>\n",
       "      <td>0.314505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-15.909103</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>532697</td>\n",
       "      <td>5161847</td>\n",
       "      <td>0</td>\n",
       "      <td>0.938939</td>\n",
       "      <td>99.808395</td>\n",
       "      <td>790.453814</td>\n",
       "      <td>0.893834</td>\n",
       "      <td>1.977307</td>\n",
       "      <td>16.122506</td>\n",
       "      <td>0.344173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284375</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-16.617979</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>763472</td>\n",
       "      <td>6447198</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988622</td>\n",
       "      <td>134.510406</td>\n",
       "      <td>1094.769867</td>\n",
       "      <td>0.977100</td>\n",
       "      <td>1.039390</td>\n",
       "      <td>8.350440</td>\n",
       "      <td>0.290261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-16.757101</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9977 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          qID      pID  y  w2v_cosine  w2v_euclidean  w2v_manhattan  \\\n",
       "0      603195  7050012  1    0.972107     144.641830    1124.871630   \n",
       "1      474183   325505  1    0.971866     131.960266    1033.670312   \n",
       "2      320545  1751825  1    0.947701      94.900002     756.378183   \n",
       "3       89798  5069949  1    0.972710     161.470459    1273.643564   \n",
       "4     1054603  2869106  1    0.965680     155.648453    1216.564726   \n",
       "...       ...      ... ..         ...            ...            ...   \n",
       "4995   128401  6127598  0    0.796978      85.670822     678.466760   \n",
       "4996  1044540  4616118  0    0.922095     157.044754    1238.354322   \n",
       "4997   486146  1137390  0    0.946438     125.126984     972.330644   \n",
       "4998   532697  5161847  0    0.938939      99.808395     790.453814   \n",
       "4999   763472  6447198  0    0.988622     134.510406    1094.769867   \n",
       "\n",
       "      w2v_tfidf_cosine  w2v_tfidf_euclidean  w2v_tfidf_manhattan  \\\n",
       "0             0.938781             2.765727            22.236694   \n",
       "1             0.985675             1.360485            11.347487   \n",
       "2             0.959522             2.236971            17.352688   \n",
       "3             0.933304             1.714253            13.493497   \n",
       "4             0.941391             1.799412            14.369308   \n",
       "...                ...                  ...                  ...   \n",
       "4995          0.555981             3.027138            24.841764   \n",
       "4996          0.603788             2.167866            17.812756   \n",
       "4997          0.882998             4.161341            34.815641   \n",
       "4998          0.893834             1.977307            16.122506   \n",
       "4999          0.977100             1.039390             8.350440   \n",
       "\n",
       "      tfidf_cosine  ...  polarity_doc  subjectivity_query  polarity_query  \\\n",
       "0         0.537439  ...      0.000000                0.00            0.00   \n",
       "1         0.745907  ...      0.450000                0.00            0.00   \n",
       "2         0.409509  ...      0.500000                0.20            0.20   \n",
       "3         0.541627  ...      0.066667                0.25            0.00   \n",
       "4         0.438115  ...      0.000000                0.00            0.00   \n",
       "...            ...  ...           ...                 ...             ...   \n",
       "4995      0.185056  ...     -0.520833                0.00            0.00   \n",
       "4996      0.140057  ...      0.156250                0.00            0.00   \n",
       "4997      0.314505  ...     -0.100000                0.10            0.00   \n",
       "4998      0.344173  ...      0.284375                0.00            0.00   \n",
       "4999      0.290261  ...      0.033333                0.05            0.15   \n",
       "\n",
       "           bm25  doc_nouns  doc_adjectives  doc_verbs  query_nouns  \\\n",
       "0    -24.655536         23               6          4            3   \n",
       "1    -33.129796         18               9          3            4   \n",
       "2    -16.699603         20               2         14            2   \n",
       "3    -27.678576         25              10          5            3   \n",
       "4    -28.497519         20               9          6            2   \n",
       "...         ...        ...             ...        ...          ...   \n",
       "4995  -8.866170         16               6         13            2   \n",
       "4996  -7.852468         25               9         16            0   \n",
       "4997 -15.909103         12               1         10            2   \n",
       "4998 -16.617979         18               8          9            3   \n",
       "4999 -16.757101         12              16          4            1   \n",
       "\n",
       "      query_adjectives  query_verbs  \n",
       "0                    1            1  \n",
       "1                    0            0  \n",
       "2                    1            1  \n",
       "3                    1            0  \n",
       "4                    2            1  \n",
       "...                ...          ...  \n",
       "4995                 1            0  \n",
       "4996                 0            1  \n",
       "4997                 0            2  \n",
       "4998                 1            0  \n",
       "4999                 3            1  \n",
       "\n",
       "[9977 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.7100000000000001\n",
      "nDCG: 0.8594455416010075\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    model='lr', \n",
    "    pca=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_search_space: list = []\n",
    "logistic_regression_search_space.append(Categorical(['l2', 'none'], name='penalty'))\n",
    "logistic_regression_search_space.append(Real(0.1, 100.0, 'log-uniform', name='C'))\n",
    "logistic_regression_search_space.append(Real(1e-6, 0.1, name='tol'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='hpo',\n",
    "    model='lr', \n",
    "    pca=0, \n",
    "    search_space=logistic_regression_search_space,\n",
    "    trials=80\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.7831890331890332\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    model='nbg', \n",
    "    pca=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.6127128427128427\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    model='mlp', \n",
    "    pca=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_search_space: list = []\n",
    "mlp_search_space.append(Categorical(['identity', 'logistic', 'tanh', 'relu'], name='activation'))\n",
    "mlp_search_space.append(Real(1e-6, 0.1, name='alpha'))\n",
    "mlp_search_space.append(Real(1e-6, 0.1, name='learning_rate_init'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/opt/anaconda3/envs/inforetrieval/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MRR: 0.021389911903328847\n",
      "Best Hyperparameters: ['relu', 0.06182287613368023, 0.088131546212749]\n",
      "MRR on test set: 0.04008374381599637\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='hpo',\n",
    "    model='mlp', \n",
    "    pca=0,\n",
    "    search_space=mlp_search_space,\n",
    "    trials=80\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.03290961769836377\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='default_fs',\n",
    "    model='svm', \n",
    "    pca=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_search_space: list = []\n",
    "svm_search_space.append(Categorical(['poly', 'rbf', 'sigmoid'], name='kernel'))\n",
    "svm_search_space.append(Real(0.1, 100.0, name='C'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MRR: 0.006591189472904975\n",
      "Best Hyperparameters: ['poly', 96.43409248718199]\n",
      "MRR on test set: 0.02065391377002617\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='hpo',\n",
    "    model='svm', \n",
    "    pca=0,\n",
    "    search_space=svm_search_space,\n",
    "    trials=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.48315889840418147\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='default_fs',\n",
    "    model='dt', \n",
    "    pca=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_search_space: list = []\n",
    "decision_tree_search_space.append(Categorical(['gini', 'entropy'], name='criterion'))\n",
    "decision_tree_search_space.append(Integer(2, 15, name='min_samples_split'))\n",
    "decision_tree_search_space.append(Integer(1, 10, name='min_samples_leaf'))\n",
    "decision_tree_search_space.append(Integer(5, 100, name='max_leaf_nodes'))\n",
    "decision_tree_search_space.append(Integer(10, 50, name='max_depth'))\n",
    "decision_tree_search_space.append(Real(0.0, 0.2, name='min_weight_fraction_leaf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MRR: 0.014240579043972797\n",
      "Best Hyperparameters: ['gini', 8, 1, 54, 50, 0.09589400710794578]\n",
      "MRR on test set: 0.031025164291920405\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='hpo',\n",
    "    model='dt', \n",
    "    pca=0,\n",
    "    search_space=decision_tree_search_space,\n",
    "    trials=80\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.01848330416627482\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='default_fs',\n",
    "    model='rf', \n",
    "    pca=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_search_space: list = []\n",
    "random_forest_search_space.append(Integer(20, 200, name='n_estimators'))\n",
    "random_forest_search_space.append(Categorical(['gini', 'entropy'], name='criterion'))\n",
    "random_forest_search_space.append(Integer(2, 15, name='min_samples_split'))\n",
    "random_forest_search_space.append(Integer(1, 10, name='min_samples_leaf'))\n",
    "random_forest_search_space.append(Integer(5, 100, name='max_leaf_nodes'))\n",
    "random_forest_search_space.append(Integer(10, 50, name='max_depth'))\n",
    "random_forest_search_space.append(Real(0.0, 0.2, name='min_weight_fraction_leaf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MRR: 0.009150207701567426\n",
      "Best Hyperparameters: [154, 'gini', 2, 5, 80, 14, 0.0403058426545757]\n",
      "MRR on test set: 0.034692053937964124\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='hpo',\n",
    "    model='rf', \n",
    "    pca=0,\n",
    "    search_space=random_forest_search_space,\n",
    "    trials=80\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.03280269179184586\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='default_fs',\n",
    "    model='ada', \n",
    "    pca=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_search_space: list = []\n",
    "ada_boost_search_space.append(Integer(20, 200, name='n_estimators'))\n",
    "ada_boost_search_space.append(Real(1e-2, 2.0, name='learning_rate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MRR: 0.01287661935132817\n",
      "Best Hyperparameters: [196, 1.8682883991749144]\n",
      "MRR on test set: 0.02859756118744077\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='hpo',\n",
    "    model='ada', \n",
    "    pca=0,\n",
    "    search_space=ada_boost_search_space,\n",
    "    trials=80\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.019908559703379892\n"
     ]
    }
   ],
   "source": [
    "pipeline.evaluate(\n",
    "    name='default_fs',\n",
    "    model='gb', \n",
    "    pca=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting_search_space: list = []\n",
    "gradient_boosting_search_space.append(Integer(20, 200, name='n_estimators'))\n",
    "gradient_boosting_search_space.append(Categorical(['friedman_mse', 'squared_error', 'mse'], name='criterion'))\n",
    "gradient_boosting_search_space.append(Integer(2, 15, name='min_samples_split'))\n",
    "gradient_boosting_search_space.append(Integer(1, 10, name='min_samples_leaf'))\n",
    "gradient_boosting_search_space.append(Integer(5, 100, name='max_leaf_nodes'))\n",
    "gradient_boosting_search_space.append(Integer(10, 50, name='max_depth'))\n",
    "gradient_boosting_search_space.append(Real(0.0, 0.2, name='min_weight_fraction_leaf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.evaluate(\n",
    "    name='hpo',\n",
    "    model='gb', \n",
    "    pca=0,\n",
    "    search_space=gradient_boosting_search_space,\n",
    "    trials=80\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>pairwise_model</th>\n",
       "      <th>pairwise_k</th>\n",
       "      <th>features</th>\n",
       "      <th>sampling_training</th>\n",
       "      <th>sampling_test</th>\n",
       "      <th>pca</th>\n",
       "      <th>MRR</th>\n",
       "      <th>MAP</th>\n",
       "      <th>nDCG</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy@50</th>\n",
       "      <th>precision@50</th>\n",
       "      <th>recall@50</th>\n",
       "      <th>f1@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\"]</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.213607</td>\n",
       "      <td>0.466847</td>\n",
       "      <td>0.880017</td>\n",
       "      <td>0.020470</td>\n",
       "      <td>0.633635</td>\n",
       "      <td>0.039658</td>\n",
       "      <td>0.243333</td>\n",
       "      <td>0.243333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.391421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_euclidean\"]</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.245864</td>\n",
       "      <td>0.728835</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>0.338052</td>\n",
       "      <td>0.009654</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_manhattan\"]</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.011349</td>\n",
       "      <td>0.245556</td>\n",
       "      <td>0.742402</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>0.322197</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_tfidf_cosine\"]</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.454008</td>\n",
       "      <td>0.605277</td>\n",
       "      <td>0.980648</td>\n",
       "      <td>0.126086</td>\n",
       "      <td>0.665912</td>\n",
       "      <td>0.212026</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.604651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_tfidf_euclidean\"]</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.427975</td>\n",
       "      <td>0.594469</td>\n",
       "      <td>0.960346</td>\n",
       "      <td>0.022986</td>\n",
       "      <td>0.220272</td>\n",
       "      <td>0.041629</td>\n",
       "      <td>0.358667</td>\n",
       "      <td>0.311060</td>\n",
       "      <td>0.425868</td>\n",
       "      <td>0.359521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>None</td>\n",
       "      <td>MLPClassifier(random_state=42)</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.559354</td>\n",
       "      <td>0.734080</td>\n",
       "      <td>0.996413</td>\n",
       "      <td>0.574642</td>\n",
       "      <td>0.318233</td>\n",
       "      <td>0.409621</td>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.610231</td>\n",
       "      <td>0.752252</td>\n",
       "      <td>0.673840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>default_fs</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.574378</td>\n",
       "      <td>0.996838</td>\n",
       "      <td>0.707617</td>\n",
       "      <td>0.326161</td>\n",
       "      <td>0.446512</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.698539</td>\n",
       "      <td>0.998102</td>\n",
       "      <td>0.821875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression(random_state=42)</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"bm25\", \"char_query\", \"tfidf_manhattan\", \"w2v...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812780</td>\n",
       "      <td>0.817026</td>\n",
       "      <td>0.996285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049830</td>\n",
       "      <td>0.094930</td>\n",
       "      <td>0.484000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.102088</td>\n",
       "      <td>0.185263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression(random_state=42)</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"bm25\", \"char_query\", \"tfidf_manhattan\", \"w2v...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812780</td>\n",
       "      <td>0.817026</td>\n",
       "      <td>0.996285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049830</td>\n",
       "      <td>0.094930</td>\n",
       "      <td>0.484000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.102088</td>\n",
       "      <td>0.185263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression(random_state=42)</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865090</td>\n",
       "      <td>0.859446</td>\n",
       "      <td>0.997135</td>\n",
       "      <td>0.993724</td>\n",
       "      <td>0.268969</td>\n",
       "      <td>0.423351</td>\n",
       "      <td>0.690667</td>\n",
       "      <td>0.993289</td>\n",
       "      <td>0.490608</td>\n",
       "      <td>0.656805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name                                    model  \\\n",
       "0          None                     LogisticRegression()   \n",
       "1          None                     LogisticRegression()   \n",
       "2          None                     LogisticRegression()   \n",
       "3          None                     LogisticRegression()   \n",
       "4          None                     LogisticRegression()   \n",
       "..          ...                                      ...   \n",
       "501        None           MLPClassifier(random_state=42)   \n",
       "502  default_fs  DecisionTreeClassifier(random_state=42)   \n",
       "503        None      LogisticRegression(random_state=42)   \n",
       "504        None      LogisticRegression(random_state=42)   \n",
       "505        None      LogisticRegression(random_state=42)   \n",
       "\n",
       "                                       hyperparameters pairwise_model  \\\n",
       "0    {'C': 1.0, 'class_weight': None, 'dual': False...           None   \n",
       "1    {'C': 1.0, 'class_weight': None, 'dual': False...           None   \n",
       "2    {'C': 1.0, 'class_weight': None, 'dual': False...           None   \n",
       "3    {'C': 1.0, 'class_weight': None, 'dual': False...           None   \n",
       "4    {'C': 1.0, 'class_weight': None, 'dual': False...           None   \n",
       "..                                                 ...            ...   \n",
       "501  {'activation': 'relu', 'alpha': 0.0001, 'batch...           None   \n",
       "502  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...           None   \n",
       "503  {'C': 1.0, 'class_weight': None, 'dual': False...           None   \n",
       "504  {'C': 1.0, 'class_weight': None, 'dual': False...           None   \n",
       "505  {'C': 1.0, 'class_weight': None, 'dual': False...           None   \n",
       "\n",
       "    pairwise_k                                           features  \\\n",
       "0         None                                     [\"w2v_cosine\"]   \n",
       "1         None                                  [\"w2v_euclidean\"]   \n",
       "2         None                                  [\"w2v_manhattan\"]   \n",
       "3         None                               [\"w2v_tfidf_cosine\"]   \n",
       "4         None                            [\"w2v_tfidf_euclidean\"]   \n",
       "..         ...                                                ...   \n",
       "501       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "502       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "503       None  [\"bm25\", \"char_query\", \"tfidf_manhattan\", \"w2v...   \n",
       "504       None  [\"bm25\", \"char_query\", \"tfidf_manhattan\", \"w2v...   \n",
       "505       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "\n",
       "     sampling_training  sampling_test  pca       MRR       MAP      nDCG  \\\n",
       "0                 9977         451680    0  0.000388  0.213607  0.466847   \n",
       "1                 9977         451680    0  0.000071  0.012244  0.245864   \n",
       "2                 9977         451680    0  0.000071  0.011349  0.245556   \n",
       "3                 9977         451680    0  0.001565  0.454008  0.605277   \n",
       "4                 9977         451680    0  0.001216  0.427975  0.594469   \n",
       "..                 ...            ...  ...       ...       ...       ...   \n",
       "501               9977         451680    0       NaN  0.559354  0.734080   \n",
       "502               9977         451680    0       NaN  0.327402  0.574378   \n",
       "503               9977         451680    0       NaN  0.812780  0.817026   \n",
       "504               9977         451680    0       NaN  0.812780  0.817026   \n",
       "505               9977         451680    0  1.000000  0.865090  0.859446   \n",
       "\n",
       "     accuracy  precision    recall        f1  accuracy@50  precision@50  \\\n",
       "0    0.880017   0.020470  0.633635  0.039658     0.243333      0.243333   \n",
       "1    0.728835   0.004897  0.338052  0.009654     0.018667      0.018667   \n",
       "2    0.742402   0.004917  0.322197  0.009686     0.016667      0.016667   \n",
       "3    0.980648   0.126086  0.665912  0.212026     0.433333      0.433333   \n",
       "4    0.960346   0.022986  0.220272  0.041629     0.358667      0.311060   \n",
       "..        ...        ...       ...       ...          ...           ...   \n",
       "501  0.996413   0.574642  0.318233  0.409621     0.676667      0.610231   \n",
       "502  0.996838   0.707617  0.326161  0.446512     0.848000      0.698539   \n",
       "503  0.996285   1.000000  0.049830  0.094930     0.484000      1.000000   \n",
       "504  0.996285   1.000000  0.049830  0.094930     0.484000      1.000000   \n",
       "505  0.997135   0.993724  0.268969  0.423351     0.690667      0.993289   \n",
       "\n",
       "     recall@50     f1@50  \n",
       "0     1.000000  0.391421  \n",
       "1     1.000000  0.036649  \n",
       "2     1.000000  0.032787  \n",
       "3     1.000000  0.604651  \n",
       "4     0.425868  0.359521  \n",
       "..         ...       ...  \n",
       "501   0.752252  0.673840  \n",
       "502   0.998102  0.821875  \n",
       "503   0.102088  0.185263  \n",
       "504   0.102088  0.185263  \n",
       "505   0.490608  0.656805  \n",
       "\n",
       "[506 rows x 20 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.utils.utils import load\n",
    "\n",
    "results = load('data/results/results.pkl')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>pairwise_model</th>\n",
       "      <th>pairwise_k</th>\n",
       "      <th>features</th>\n",
       "      <th>sampling_training</th>\n",
       "      <th>sampling_test</th>\n",
       "      <th>pca</th>\n",
       "      <th>MRR</th>\n",
       "      <th>MAP</th>\n",
       "      <th>nDCG</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy@50</th>\n",
       "      <th>precision@50</th>\n",
       "      <th>recall@50</th>\n",
       "      <th>f1@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>default</td>\n",
       "      <td>LogisticRegression(random_state=42)</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038060</td>\n",
       "      <td>0.865090</td>\n",
       "      <td>0.859446</td>\n",
       "      <td>0.997135</td>\n",
       "      <td>0.993724</td>\n",
       "      <td>0.268969</td>\n",
       "      <td>0.423351</td>\n",
       "      <td>0.690667</td>\n",
       "      <td>0.993289</td>\n",
       "      <td>0.490608</td>\n",
       "      <td>0.656805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>default</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.874882</td>\n",
       "      <td>0.875631</td>\n",
       "      <td>0.997173</td>\n",
       "      <td>0.995943</td>\n",
       "      <td>0.278029</td>\n",
       "      <td>0.434706</td>\n",
       "      <td>0.718000</td>\n",
       "      <td>0.995851</td>\n",
       "      <td>0.532741</td>\n",
       "      <td>0.694143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>default</td>\n",
       "      <td>MLPClassifier(random_state=42)</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020241</td>\n",
       "      <td>0.559354</td>\n",
       "      <td>0.734080</td>\n",
       "      <td>0.996413</td>\n",
       "      <td>0.574642</td>\n",
       "      <td>0.318233</td>\n",
       "      <td>0.409621</td>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.610231</td>\n",
       "      <td>0.752252</td>\n",
       "      <td>0.673840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>default</td>\n",
       "      <td>SVC(probability=True, random_state=42)</td>\n",
       "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031905</td>\n",
       "      <td>0.775297</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.997208</td>\n",
       "      <td>0.994129</td>\n",
       "      <td>0.287656</td>\n",
       "      <td>0.446201</td>\n",
       "      <td>0.748667</td>\n",
       "      <td>0.993776</td>\n",
       "      <td>0.561547</td>\n",
       "      <td>0.717603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>default</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.574378</td>\n",
       "      <td>0.996838</td>\n",
       "      <td>0.707617</td>\n",
       "      <td>0.326161</td>\n",
       "      <td>0.446512</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.698539</td>\n",
       "      <td>0.998102</td>\n",
       "      <td>0.821875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>default</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018070</td>\n",
       "      <td>0.660944</td>\n",
       "      <td>0.794175</td>\n",
       "      <td>0.997419</td>\n",
       "      <td>0.991803</td>\n",
       "      <td>0.342582</td>\n",
       "      <td>0.509259</td>\n",
       "      <td>0.859333</td>\n",
       "      <td>0.992895</td>\n",
       "      <td>0.729765</td>\n",
       "      <td>0.841234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>default</td>\n",
       "      <td>AdaBoostClassifier(random_state=42)</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032657</td>\n",
       "      <td>0.827516</td>\n",
       "      <td>0.854278</td>\n",
       "      <td>0.997219</td>\n",
       "      <td>0.992278</td>\n",
       "      <td>0.291053</td>\n",
       "      <td>0.450088</td>\n",
       "      <td>0.718667</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.532438</td>\n",
       "      <td>0.692868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>default</td>\n",
       "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023998</td>\n",
       "      <td>0.723875</td>\n",
       "      <td>0.826181</td>\n",
       "      <td>0.997250</td>\n",
       "      <td>0.992481</td>\n",
       "      <td>0.298981</td>\n",
       "      <td>0.459530</td>\n",
       "      <td>0.774667</td>\n",
       "      <td>0.991903</td>\n",
       "      <td>0.594660</td>\n",
       "      <td>0.743551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name                                        model  \\\n",
       "432  default          LogisticRegression(random_state=42)   \n",
       "433  default                                 GaussianNB()   \n",
       "434  default               MLPClassifier(random_state=42)   \n",
       "435  default       SVC(probability=True, random_state=42)   \n",
       "436  default      DecisionTreeClassifier(random_state=42)   \n",
       "437  default      RandomForestClassifier(random_state=42)   \n",
       "438  default          AdaBoostClassifier(random_state=42)   \n",
       "439  default  GradientBoostingClassifier(random_state=42)   \n",
       "\n",
       "                                       hyperparameters pairwise_model  \\\n",
       "432  {'C': 1.0, 'class_weight': None, 'dual': False...           None   \n",
       "433           {'priors': None, 'var_smoothing': 1e-09}           None   \n",
       "434  {'activation': 'relu', 'alpha': 0.0001, 'batch...           None   \n",
       "435  {'C': 1.0, 'break_ties': False, 'cache_size': ...           None   \n",
       "436  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...           None   \n",
       "437  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...           None   \n",
       "438  {'algorithm': 'SAMME.R', 'base_estimator': Non...           None   \n",
       "439  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...           None   \n",
       "\n",
       "    pairwise_k                                           features  \\\n",
       "432       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "433       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "434       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "435       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "436       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "437       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "438       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "439       None  [\"w2v_cosine\", \"w2v_euclidean\", \"w2v_manhattan...   \n",
       "\n",
       "     sampling_training  sampling_test  pca       MRR       MAP      nDCG  \\\n",
       "432               9977         451680    0  0.038060  0.865090  0.859446   \n",
       "433               9977         451680    0  0.036072  0.874882  0.875631   \n",
       "434               9977         451680    0  0.020241  0.559354  0.734080   \n",
       "435               9977         451680    0  0.031905  0.775297  0.826087   \n",
       "436               9977         451680    0  0.004835  0.327402  0.574378   \n",
       "437               9977         451680    0  0.018070  0.660944  0.794175   \n",
       "438               9977         451680    0  0.032657  0.827516  0.854278   \n",
       "439               9977         451680    0  0.023998  0.723875  0.826181   \n",
       "\n",
       "     accuracy  precision    recall        f1  accuracy@50  precision@50  \\\n",
       "432  0.997135   0.993724  0.268969  0.423351     0.690667      0.993289   \n",
       "433  0.997173   0.995943  0.278029  0.434706     0.718000      0.995851   \n",
       "434  0.996413   0.574642  0.318233  0.409621     0.676667      0.610231   \n",
       "435  0.997208   0.994129  0.287656  0.446201     0.748667      0.993776   \n",
       "436  0.996838   0.707617  0.326161  0.446512     0.848000      0.698539   \n",
       "437  0.997419   0.991803  0.342582  0.509259     0.859333      0.992895   \n",
       "438  0.997219   0.992278  0.291053  0.450088     0.718667      0.991667   \n",
       "439  0.997250   0.992481  0.298981  0.459530     0.774667      0.991903   \n",
       "\n",
       "     recall@50     f1@50  \n",
       "432   0.490608  0.656805  \n",
       "433   0.532741  0.694143  \n",
       "434   0.752252  0.673840  \n",
       "435   0.561547  0.717603  \n",
       "436   0.998102  0.821875  \n",
       "437   0.729765  0.841234  \n",
       "438   0.532438  0.692868  \n",
       "439   0.594660  0.743551  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['name'] == 'default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection and Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>pairwise_model</th>\n",
       "      <th>pairwise_k</th>\n",
       "      <th>features</th>\n",
       "      <th>sampling_training</th>\n",
       "      <th>sampling_test</th>\n",
       "      <th>pca</th>\n",
       "      <th>MRR</th>\n",
       "      <th>MAP</th>\n",
       "      <th>nDCG</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy@50</th>\n",
       "      <th>precision@50</th>\n",
       "      <th>recall@50</th>\n",
       "      <th>f1@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>default_fs</td>\n",
       "      <td>LogisticRegression(random_state=42)</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040327</td>\n",
       "      <td>0.883309</td>\n",
       "      <td>0.872551</td>\n",
       "      <td>0.997186</td>\n",
       "      <td>0.995992</td>\n",
       "      <td>0.281427</td>\n",
       "      <td>0.438852</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.995662</td>\n",
       "      <td>0.503289</td>\n",
       "      <td>0.668609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>default_fs</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031908</td>\n",
       "      <td>0.861935</td>\n",
       "      <td>0.865709</td>\n",
       "      <td>0.996980</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>0.228766</td>\n",
       "      <td>0.372007</td>\n",
       "      <td>0.667333</td>\n",
       "      <td>0.995025</td>\n",
       "      <td>0.445931</td>\n",
       "      <td>0.615858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>default_fs</td>\n",
       "      <td>MLPClassifier(random_state=42)</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034157</td>\n",
       "      <td>0.760575</td>\n",
       "      <td>0.834966</td>\n",
       "      <td>0.997306</td>\n",
       "      <td>0.958264</td>\n",
       "      <td>0.325028</td>\n",
       "      <td>0.485412</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.962162</td>\n",
       "      <td>0.628975</td>\n",
       "      <td>0.760684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>default_fs</td>\n",
       "      <td>SVC(probability=True, random_state=42)</td>\n",
       "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032910</td>\n",
       "      <td>0.799849</td>\n",
       "      <td>0.839896</td>\n",
       "      <td>0.997257</td>\n",
       "      <td>0.992523</td>\n",
       "      <td>0.300680</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.741333</td>\n",
       "      <td>0.991935</td>\n",
       "      <td>0.561644</td>\n",
       "      <td>0.717201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>default_fs</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.411414</td>\n",
       "      <td>0.634840</td>\n",
       "      <td>0.997308</td>\n",
       "      <td>0.935127</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>0.492911</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.933444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>default_fs</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018483</td>\n",
       "      <td>0.617130</td>\n",
       "      <td>0.774883</td>\n",
       "      <td>0.997396</td>\n",
       "      <td>0.994966</td>\n",
       "      <td>0.335787</td>\n",
       "      <td>0.502117</td>\n",
       "      <td>0.885333</td>\n",
       "      <td>0.994575</td>\n",
       "      <td>0.764951</td>\n",
       "      <td>0.864780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>default_fs</td>\n",
       "      <td>AdaBoostClassifier(random_state=42)</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032803</td>\n",
       "      <td>0.828655</td>\n",
       "      <td>0.857594</td>\n",
       "      <td>0.997303</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.312571</td>\n",
       "      <td>0.475452</td>\n",
       "      <td>0.744667</td>\n",
       "      <td>0.994231</td>\n",
       "      <td>0.576366</td>\n",
       "      <td>0.729711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>default_fs</td>\n",
       "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019909</td>\n",
       "      <td>0.677873</td>\n",
       "      <td>0.814548</td>\n",
       "      <td>0.997314</td>\n",
       "      <td>0.992870</td>\n",
       "      <td>0.315402</td>\n",
       "      <td>0.478728</td>\n",
       "      <td>0.831333</td>\n",
       "      <td>0.992366</td>\n",
       "      <td>0.676203</td>\n",
       "      <td>0.804331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name                                        model  \\\n",
       "440  default_fs          LogisticRegression(random_state=42)   \n",
       "441  default_fs                                 GaussianNB()   \n",
       "442  default_fs               MLPClassifier(random_state=42)   \n",
       "443  default_fs       SVC(probability=True, random_state=42)   \n",
       "444  default_fs      DecisionTreeClassifier(random_state=42)   \n",
       "445  default_fs      RandomForestClassifier(random_state=42)   \n",
       "446  default_fs          AdaBoostClassifier(random_state=42)   \n",
       "447  default_fs  GradientBoostingClassifier(random_state=42)   \n",
       "\n",
       "                                       hyperparameters pairwise_model  \\\n",
       "440  {'C': 1.0, 'class_weight': None, 'dual': False...           None   \n",
       "441           {'priors': None, 'var_smoothing': 1e-09}           None   \n",
       "442  {'activation': 'relu', 'alpha': 0.0001, 'batch...           None   \n",
       "443  {'C': 1.0, 'break_ties': False, 'cache_size': ...           None   \n",
       "444  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...           None   \n",
       "445  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...           None   \n",
       "446  {'algorithm': 'SAMME.R', 'base_estimator': Non...           None   \n",
       "447  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...           None   \n",
       "\n",
       "    pairwise_k                                           features  \\\n",
       "440       None  [\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...   \n",
       "441       None  [\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...   \n",
       "442       None  [\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...   \n",
       "443       None  [\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...   \n",
       "444       None  [\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...   \n",
       "445       None  [\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...   \n",
       "446       None  [\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...   \n",
       "447       None  [\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...   \n",
       "\n",
       "     sampling_training  sampling_test  pca       MRR       MAP      nDCG  \\\n",
       "440               9977         451680    0  0.040327  0.883309  0.872551   \n",
       "441               9977         451680    0  0.031908  0.861935  0.865709   \n",
       "442               9977         451680    0  0.034157  0.760575  0.834966   \n",
       "443               9977         451680    0  0.032910  0.799849  0.839896   \n",
       "444               9977         451680    0  0.000077  0.411414  0.634840   \n",
       "445               9977         451680    0  0.018483  0.617130  0.774883   \n",
       "446               9977         451680    0  0.032803  0.828655  0.857594   \n",
       "447               9977         451680    0  0.019909  0.677873  0.814548   \n",
       "\n",
       "     accuracy  precision    recall        f1  accuracy@50  precision@50  \\\n",
       "440  0.997186   0.995992  0.281427  0.438852     0.696667      0.995662   \n",
       "441  0.996980   0.995074  0.228766  0.372007     0.667333      0.995025   \n",
       "442  0.997306   0.958264  0.325028  0.485412     0.776000      0.962162   \n",
       "443  0.997257   0.992523  0.300680  0.461538     0.741333      0.991935   \n",
       "444  0.997308   0.935127  0.334655  0.492911     0.973333      0.933444   \n",
       "445  0.997396   0.994966  0.335787  0.502117     0.885333      0.994575   \n",
       "446  0.997303   0.992806  0.312571  0.475452     0.744667      0.994231   \n",
       "447  0.997314   0.992870  0.315402  0.478728     0.831333      0.992366   \n",
       "\n",
       "     recall@50     f1@50  \n",
       "440   0.503289  0.668609  \n",
       "441   0.445931  0.615858  \n",
       "442   0.628975  0.760684  \n",
       "443   0.561644  0.717201  \n",
       "444   1.000000  0.965577  \n",
       "445   0.764951  0.864780  \n",
       "446   0.576366  0.729711  \n",
       "447   0.676203  0.804331  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['name'] == 'default_fs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection and Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>pairwise_model</th>\n",
       "      <th>pairwise_k</th>\n",
       "      <th>features</th>\n",
       "      <th>sampling_training</th>\n",
       "      <th>sampling_test</th>\n",
       "      <th>pca</th>\n",
       "      <th>MRR</th>\n",
       "      <th>MAP</th>\n",
       "      <th>nDCG</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy@50</th>\n",
       "      <th>precision@50</th>\n",
       "      <th>recall@50</th>\n",
       "      <th>f1@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>hpo</td>\n",
       "      <td>LogisticRegression(C=0.17050983070448095, rand...</td>\n",
       "      <td>{'C': 0.17050983070448095, 'class_weight': Non...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040325</td>\n",
       "      <td>0.883308</td>\n",
       "      <td>0.872752</td>\n",
       "      <td>0.997186</td>\n",
       "      <td>0.995992</td>\n",
       "      <td>0.281427</td>\n",
       "      <td>0.438852</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.995662</td>\n",
       "      <td>0.503289</td>\n",
       "      <td>0.668609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>hpo</td>\n",
       "      <td>MLPClassifier(alpha=0.06182287613368023, learn...</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.061822876133...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040084</td>\n",
       "      <td>0.887354</td>\n",
       "      <td>0.873820</td>\n",
       "      <td>0.997151</td>\n",
       "      <td>0.995859</td>\n",
       "      <td>0.272367</td>\n",
       "      <td>0.427746</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.995614</td>\n",
       "      <td>0.495093</td>\n",
       "      <td>0.661326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>hpo</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=50, max_leaf_...</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031025</td>\n",
       "      <td>0.838926</td>\n",
       "      <td>0.852904</td>\n",
       "      <td>0.997591</td>\n",
       "      <td>0.992733</td>\n",
       "      <td>0.386750</td>\n",
       "      <td>0.556642</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>0.993569</td>\n",
       "      <td>0.685144</td>\n",
       "      <td>0.811024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>hpo</td>\n",
       "      <td>RandomForestClassifier(max_depth=14, max_leaf_...</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034692</td>\n",
       "      <td>0.805156</td>\n",
       "      <td>0.853002</td>\n",
       "      <td>0.997509</td>\n",
       "      <td>0.993837</td>\n",
       "      <td>0.365232</td>\n",
       "      <td>0.534161</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.993289</td>\n",
       "      <td>0.673493</td>\n",
       "      <td>0.802712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>hpo</td>\n",
       "      <td>AdaBoostClassifier(learning_rate=1.86828839917...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...</td>\n",
       "      <td>9977</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028598</td>\n",
       "      <td>0.810201</td>\n",
       "      <td>0.843611</td>\n",
       "      <td>0.997162</td>\n",
       "      <td>0.991870</td>\n",
       "      <td>0.276331</td>\n",
       "      <td>0.432241</td>\n",
       "      <td>0.707333</td>\n",
       "      <td>0.991285</td>\n",
       "      <td>0.511236</td>\n",
       "      <td>0.674574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name                                              model  \\\n",
       "448  hpo  LogisticRegression(C=0.17050983070448095, rand...   \n",
       "449  hpo  MLPClassifier(alpha=0.06182287613368023, learn...   \n",
       "451  hpo  DecisionTreeClassifier(max_depth=50, max_leaf_...   \n",
       "452  hpo  RandomForestClassifier(max_depth=14, max_leaf_...   \n",
       "454  hpo  AdaBoostClassifier(learning_rate=1.86828839917...   \n",
       "\n",
       "                                       hyperparameters pairwise_model  \\\n",
       "448  {'C': 0.17050983070448095, 'class_weight': Non...           None   \n",
       "449  {'activation': 'relu', 'alpha': 0.061822876133...           None   \n",
       "451  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...           None   \n",
       "452  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...           None   \n",
       "454  {'algorithm': 'SAMME.R', 'base_estimator': Non...           None   \n",
       "\n",
       "    pairwise_k                                           features  \\\n",
       "448       None  [\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...   \n",
       "449       None  [\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...   \n",
       "451       None  [\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...   \n",
       "452       None  [\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...   \n",
       "454       None  [\"bert_cosine\", \"bm25\", \"char_query\", \"tfidf_m...   \n",
       "\n",
       "     sampling_training  sampling_test  pca       MRR       MAP      nDCG  \\\n",
       "448               9977         451680    0  0.040325  0.883308  0.872752   \n",
       "449               9977         451680    0  0.040084  0.887354  0.873820   \n",
       "451               9977         451680    0  0.031025  0.838926  0.852904   \n",
       "452               9977         451680    0  0.034692  0.805156  0.853002   \n",
       "454               9977         451680    0  0.028598  0.810201  0.843611   \n",
       "\n",
       "     accuracy  precision    recall        f1  accuracy@50  precision@50  \\\n",
       "448  0.997186   0.995992  0.281427  0.438852     0.696667      0.995662   \n",
       "449  0.997151   0.995859  0.272367  0.427746     0.690000      0.995614   \n",
       "451  0.997591   0.992733  0.386750  0.556642     0.808000      0.993569   \n",
       "452  0.997509   0.993837  0.365232  0.534161     0.806000      0.993289   \n",
       "454  0.997162   0.991870  0.276331  0.432241     0.707333      0.991285   \n",
       "\n",
       "     recall@50     f1@50  \n",
       "448   0.503289  0.668609  \n",
       "449   0.495093  0.661326  \n",
       "451   0.685144  0.811024  \n",
       "452   0.673493  0.802712  \n",
       "454   0.511236  0.674574  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['name'] == 'hpo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(results[results['name'] == 'pca_values']['MRR'].iloc[1:])), results[results['name'] == 'pca_values']['MRR'].iloc[1:])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15e7f6431c3efcc25ffb982d882caeeee1a07ee55caab724c679dfe0992cca8b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
